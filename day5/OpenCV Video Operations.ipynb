{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Video from WebCam\n",
    "We use 0 as parameter for default webcam of a computer. If you have another camera attached, you can change parameter number.\n",
    "\n",
    "cv2 has a function that check if camera object can access camera or source is opened using `cap.isOpened()`\n",
    "`cap.read()` function return 2 values, first one is boolean that if cam object is opened. We can ignore that using `_` sign. Second value is image.\n",
    "\n",
    "We will show image using `cv2.imshow()`. In next step `cv2.waitKey()` is used to listen a key enter. We have set `q` as key. So on press key, if that is '`q`. It breaks the while loop and `cap.release()` used to release camera and we destroy/close all camera windows using `cv2.destroyAllWindows()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    _, img = cap.read()\n",
    "    cv2.imshow(\"image window\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read video file\n",
    "For reading a video file, we just need to enter path of video file such as\n",
    "```\n",
    "cap = cv2.VideoCapture(\"YOUR_VIDEO_PATH\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"video/myvideo.avi\")\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    _, img = cap.read()\n",
    "    cv2.imshow(\"image window\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get video Details\n",
    "We can get Video details such as `FPS` and some other details such as `frame width`, `frame height`, `no of frames in video`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 1920.0  - Height: 1080.0  - FPS: 30.0  - No. Frames: 501\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"videos/myvideo.avi\")\n",
    "# Video frame width(image width from video)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "\n",
    "# Video frame height\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "# Frames per second\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Number of frames in video\n",
    "num_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "print(\"Width:\", width, \" - Height:\", height, \" - FPS:\", fps, \" - No. Frames:\", n_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection and Gradients\n",
    "\n",
    "Edge detection is used to get bounderies of objects in image. It is very useful with you want to apply some proeprocessing on data. Here we have a code which takes video feed from web cam and apply some algorithms on it. And we show it.\n",
    "\n",
    "Theses are some simple algos for getting edges and shapes from image.\n",
    "\n",
    "If you want to use a video file instead, you can change first line as follows\n",
    "\n",
    "`cap = cv2.VideoCapture(\"YOUR_VIDEO_PATH\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    # Apply laplacian algorithm on image and store in variable\n",
    "    laplacian = cv2.Laplacian(frame, cv2.CV_64F)\n",
    "    \n",
    "    # Apply sobelx\n",
    "    sobelx = cv2.Sobel(frame, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    \n",
    "    # Apply sobelY\n",
    "    sobely = cv2.Sobel(frame, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "    # Apply canny to get all edges\n",
    "    edges = cv2.Canny(frame, 100, 200)\n",
    "    \n",
    "    # Show all frames processed\n",
    "    # original windows\n",
    "    cv2.imshow('orginal', frame)\n",
    "    # laplacian\n",
    "    cv2.imshow('laplacian', laplacian)\n",
    "    # sobelx and sobely\n",
    "    cv2.imshow('sobelx', sobelx)\n",
    "    cv2.imshow('sobely', sobely)\n",
    "    # Edges\n",
    "    cv2.imshow('edges', edges)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
