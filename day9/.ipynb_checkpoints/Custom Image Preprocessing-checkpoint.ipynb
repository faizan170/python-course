{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing: alpine sea holly\n",
      "[INFO] Processing: anthurium\n",
      "[INFO] Processing: artichoke\n",
      "[INFO] Processing: azalea\n",
      "[INFO] Processing: ball moss\n",
      "[INFO] Processing: balloon flower\n",
      "[INFO] Processing: barbeton daisy\n",
      "[INFO] Processing: bearded iris\n",
      "[INFO] Processing: bee balm\n",
      "[INFO] Processing: bird of paradise\n",
      "[INFO] Processing: bishop of llandaff\n",
      "[INFO] Processing: black-eyed susan\n",
      "[INFO] Processing: blackberry lily\n",
      "[INFO] Processing: blanket flower\n",
      "[INFO] Processing: bolero deep blue\n",
      "[INFO] Processing: bougainvillea\n",
      "[INFO] Processing: bromelia\n",
      "[INFO] Processing: buttercup\n",
      "[INFO] Processing: californian poppy\n",
      "[INFO] Processing: camellia\n",
      "[INFO] Processing: canna lily\n",
      "[INFO] Processing: canterbury bells\n",
      "[INFO] Processing: cape flower\n",
      "[INFO] Processing: carnation\n",
      "[INFO] Processing: cautleya spicata\n",
      "[INFO] Processing: clematis\n",
      "[INFO] Processing: colt's foot\n",
      "[INFO] Processing: columbine\n",
      "[INFO] Processing: common dandelion\n",
      "[INFO] Processing: corn poppy\n",
      "[INFO] Processing: cyclamen\n",
      "[INFO] Processing: daffodil\n",
      "[INFO] Processing: desert-rose\n",
      "[INFO] Processing: english marigold\n",
      "[INFO] Processing: fire lily\n",
      "[INFO] Processing: foxglove\n",
      "[INFO] Processing: frangipani\n",
      "[INFO] Processing: fritillary\n",
      "[INFO] Processing: garden phlox\n",
      "[INFO] Processing: gaura\n",
      "[INFO] Processing: gazania\n",
      "[INFO] Processing: geranium\n",
      "[INFO] Processing: giant white arum lily\n",
      "[INFO] Processing: globe thistle\n",
      "[INFO] Processing: globe-flower\n",
      "[INFO] Processing: grape hyacinth\n",
      "[INFO] Processing: great masterwort\n",
      "[INFO] Processing: hard-leaved pocket orchid\n",
      "[INFO] Processing: hibiscus\n",
      "[INFO] Processing: hippeastrum\n",
      "[INFO] Processing: japanese anemone\n",
      "[INFO] Processing: king protea\n",
      "[INFO] Processing: lenten rose\n",
      "[INFO] Processing: lotus\n",
      "[INFO] Processing: love in the mist\n",
      "[INFO] Processing: magnolia\n",
      "[INFO] Processing: mallow\n",
      "[INFO] Processing: marigold\n",
      "[INFO] Processing: mexican aster\n",
      "[INFO] Processing: mexican petunia\n",
      "[INFO] Processing: monkshood\n",
      "[INFO] Processing: moon orchid\n",
      "[INFO] Processing: morning glory\n",
      "[INFO] Processing: orange dahlia\n",
      "[INFO] Processing: osteospermum\n",
      "[INFO] Processing: oxeye daisy\n",
      "[INFO] Processing: passion flower\n",
      "[INFO] Processing: pelargonium\n",
      "[INFO] Processing: peruvian lily\n",
      "[INFO] Processing: petunia\n",
      "[INFO] Processing: pincushion flower\n",
      "[INFO] Processing: pink primrose\n",
      "[INFO] Processing: pink-yellow dahlia\n",
      "[INFO] Processing: poinsettia\n",
      "[INFO] Processing: primula\n",
      "[INFO] Processing: prince of wales feathers\n",
      "[INFO] Processing: purple coneflower\n",
      "[INFO] Processing: red ginger\n",
      "[INFO] Processing: rose\n",
      "[INFO] Processing: ruby-lipped cattleya\n",
      "[INFO] Processing: siam tulip\n",
      "[INFO] Processing: silverbush\n",
      "[INFO] Processing: snapdragon\n",
      "[INFO] Processing: spear thistle\n",
      "[INFO] Processing: spring crocus\n",
      "[INFO] Processing: stemless gentian\n",
      "[INFO] Processing: sunflower\n",
      "[INFO] Processing: sweet pea\n",
      "[INFO] Processing: sweet william\n",
      "[INFO] Processing: sword lily\n",
      "[INFO] Processing: thorn apple\n",
      "[INFO] Processing: tiger lily\n",
      "[INFO] Processing: toad lily\n",
      "[INFO] Processing: tree mallow\n",
      "[INFO] Processing: tree poppy\n",
      "[INFO] Processing: trumpet creeper\n",
      "[INFO] Processing: wallflower\n",
      "[INFO] Processing: water lily\n",
      "[INFO] Processing: watercress\n",
      "[INFO] Processing: wild pansy\n",
      "[INFO] Processing: windflower\n",
      "[INFO] Processing: yellow iris\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"flower_photos\"\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "\n",
    "TRAIN_DATA = []\n",
    "TRAIN_LABELS = []\n",
    "\n",
    "for i, directory in enumerate(os.listdir(DATA_DIR)):\n",
    "    print(\"[INFO] Processing:\", directory)\n",
    "    for img in os.listdir(os.path.join(DATA_DIR, directory)):\n",
    "        image = cv2.imread(os.path.join(DATA_DIR, directory, img))\n",
    "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        TRAIN_DATA.append(image)\n",
    "        TRAIN_LABELS.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = np.array(TRAIN_DATA)\n",
    "TRAIN_LABELS = np.array(TRAIN_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192, 200, 200, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_LABELS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, 8, 8, 8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_LABELS[630:640]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABELS = np_utils.to_categorical(TRAIN_LABELS, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192, 102)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_LABELS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_data.npy\", TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_labels.npy\", TRAIN_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (3670, 150, 150, 3)\n",
      "Y_train: (3670, 5)\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 5\n",
    "\n",
    "X_train = TRAIN_DATA.astype('float32')\n",
    "X_train /= 255\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('Y_train:', TRAIN_LABELS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2569, 150, 150, 3)\n",
      "(1101, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, TRAIN_LABELS, test_size=0.3)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 150, 150, 3)\n",
      "(551, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\faizan\\anaconda3\\envs\\python361\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, BatchNormalization, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Adding COnv layer 64 filters\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 1), padding='same', \\\n",
    "                 input_shape=(150, 150, 3), name='conv2d_1'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same', name='maxpool_1'))\n",
    "\n",
    "\n",
    "# Adding CONV Layers\n",
    "model.add(Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', name='conv2d_2'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same', name='maxpool_2'))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', name='conv2d_3'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same', name='maxpool_3'))\n",
    "\n",
    "model.add(Flatten(name='flatten_1'))\n",
    "\n",
    "model.add(Dense(256, activation='relu', name='dense_1'))\n",
    "model.add(Dropout(0.4, name='dropout_1'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(5, activation='softmax', name='dense_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 64)      4864      \n",
      "_________________________________________________________________\n",
      "maxpool_1 (MaxPooling2D)     (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 128)       204928    \n",
      "_________________________________________________________________\n",
      "maxpool_2 (MaxPooling2D)     (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 38, 38, 128)       409728    \n",
      "_________________________________________________________________\n",
      "maxpool_3 (MaxPooling2D)     (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 46208)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               11829504  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 12,451,333\n",
      "Trainable params: 12,450,821\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\faizan\\anaconda3\\envs\\python361\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "2569/2569 [==============================] - 1183s 460ms/step - loss: 1.6454 - acc: 0.3394\n",
      "Epoch 2/5\n",
      "2176/2569 [========================>.....] - ETA: 3:09 - loss: 1.5773 - acc: 0.3534"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "history = model.fit(X_train, Y_train, epochs=5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
